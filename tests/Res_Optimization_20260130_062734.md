# RAGAS-testituloksien Analyysi ja Optimointiehdotukset

## üìä Yhteenveto tuloksista
- Kokonaisarvio: Erinomainen pohja tuotantoon. Suurin kehityskohde on Vastauksen relevanssi (0.6888), joka laahaa muun laadun per√§ss√§ ja aiheuttaa konkreettisia virheit√§ (mm. linkki- ja sis√§lt√∂hallusinaatiot).
- Taulukko metriikoista (tulos, tavoite, status)

| Metriikka | Tulos | Tavoite | Status |
|---|---:|---:|:--:|
| Totuudenmukaisuus | 0.8711 | ‚â• 0.90 | ‚ö†Ô∏è |
| Vastauksen relevanssi | 0.6888 | ‚â• 0.85 | ‚ùå |
| Kontekstin kattavuus | 0.9259 | ‚â• 0.90 | ‚úÖ |
| Kontekstin tarkkuus | 0.8318 | ‚â• 0.85 | ‚ö†Ô∏è |
| RAGAS-keskiarvo | 0.8294 | ‚â• 0.85 | ‚ö†Ô∏è |
| Kustannus/testi | $0.0400 | ‚â§ $0.05 | ‚úÖ |
| Input-tokenit | 221,544 | -25‚Äì40% | ‚ö†Ô∏è |

### Keskeiset havainnot
- ‚úÖ Vahvuudet
  - Eritt√§in hyv√§ kontekstin kattavuus (0.9259): relevantit l√§hteet l√∂ytyv√§t.
  - Korkea totuudenmukaisuus (0.8711): generointi hy√∂dynt√§√§ kontekstia p√§√§osin oikein.
  - Kustannustaso matala per testi.

- ‚ö†Ô∏è Kehityskohteet
  - Vastauksen relevanssi (0.6888): vastauksiin p√§√§tyy kysymykseen kuulumattomia lis√§tietoja ja virheellisi√§ yksityiskohtia.
  - Kontekstin tarkkuus (0.8318): mukana on joskus liikaa tai sivuavaa kontekstia, joka sekoittaa generaatiota.
  - Yksitt√§iset virheet: URL-hallusinaatiot (login.netvisor.fi vs suomi.netvisor.fi), extra-sis√§lt√∂ (esim. ‚Äúkuljetetun tavaran m√§√§r√§‚Äù), v√§√§r√§ viittausl√§hde (YouTube-linkit), ep√§m√§√§r√§iset vastuut (yhteystiedot).

## üéØ P√§√§ongelma
- Yksityiskohtainen ongelman kuvaus
  - Relevanssi j√§√§ matalaksi, koska generaattori ei ole riitt√§v√§n vahvasti ‚Äúankkuroitu‚Äù kontekstiin. T√§m√§ johtaa:
    - URL- ja l√§hdehallusinaatioihin, kun malli t√§ydent√§√§ muististaan (esim. Testi #3: login.netvisor.fi vs GT: suomi.netvisor.fi; Testi #15: ohjeiden l√§hteeksi dokumentti, vaikka GT vaatii YouTube-linkit).
    - Off-topic-lis√§yksiin, jotka eiv√§t vastaa kysymykseen (Testi #4: osallistujien lis√§ksi ‚Äúkuljetetun tavaran m√§√§r√§‚Äù).
    - Ep√§tarkkoihin tulkintoihin erityisehdoista (Testi #11: poikkeustilanteiden korvaukset kuvattu yleisesti eik√§ GT:n rajauksen mukaan).
  - Retrieval tuo kattavan materiaalin, mutta chunkit ovat osin liian laajoja ja re-rankkaus ei aina nosta t√§sm√§llisint√§ p√§tk√§√§ ylimm√§ksi ‚Üí generaattori poimii v√§√§ri√§ yksityiskohtia.
  - Prompt ei kiell√§ eksplisiittisesti keksittyj√§ linkkej√§/termej√§ eik√§ pakota vastausta rajatusti ‚Äúvain kontekstista‚Äù.

- Konkreettiset esimerkit
  - #3 URL: ‚Äúhttps://login.netvisor.fi‚Äù vs GT: ‚Äúhttps://suomi.netvisor.fi‚Äù
  - #4 Off-topic: osallistujat ‚Üí lis√§tty ‚Äúkuljetetun tavaran m√§√§r√§‚Äù
  - #11 Yleistys: korvausperiaatteet kuvattu yleisesti, ei GT:n tapausta vasten
  - #15 L√§hde: dokumentti vs GT: YouTube-linkit
  - #18 Vastuuroolit: ep√§m√§√§r√§inen, ei GT:n mukaisia selkeit√§ ohjaavia rooleja

## üîß Optimointiehdotukset
- Priorisoidut toimenpiteet (P1, P2, P3)
- Jokaiselle: ongelma, ratkaisu, koodi, arvioitu vaikutus

1) P1: ‚ÄúVain kontekstista‚Äù -prompt + URL-/l√§hde-whitelist-guardrail
- Ongelma: Generaattori lis√§√§ keksittyj√§ linkkej√§/termej√§ ja ylitulkitsee.
- Ratkaisu: 
  - Prompt, joka:
    - Saa vastata vain kontekstissa esiintyvill√§ faktoilla, URL:illa ja termeill√§.
    - Kielt√§√§ ulkoiset l√§hteet ja arvaamisen; jos tieto puuttuu, palauttaa ‚ÄúEi l√∂ydy kontekstista‚Äù.
  - Post-prosessor, joka pudottaa vastauksesta kaikki URL:it ja viittaukset, joita ei l√∂ydy kontekstista (whitelist).
- Koodi (Python, esimerkkirunko):

```python
import re

ALLOWED_URL_PATTERN = re.compile(r'https?://[a-z0-9\.\-_/]+', re.I)

def extract_allowed_urls(contexts: list[str]) -> set[str]:
    urls = set()
    for c in contexts:
        urls.update(ALLOWED_URL_PATTERN.findall(c))
    return urls

def strip_disallowed_urls(answer: str, allowed: set[str]) -> str:
    def repl(m):
        url = m.group(0)
        return url if url in allowed else ''
    return ALLOWED_URL_PATTERN.sub(repl, answer)

PROMPT = """
Vastaa VAIN alla olevasta kontekstista l√∂ytyviin tietoihin. 
- √Ñl√§ k√§yt√§ mallin muistia.
- K√§yt√§ vain kontekstissa esiintyvi√§ URL-osoitteita, koodeja ja termej√§.
- Jos vastausta ei l√∂ydy kontekstista, vastaa: "Ei l√∂ydy kontekstista."

Konteksti:
{context}

Kysymys:
{question}

Muotoile vastaus suoraan kysymykseen, ilman ylim√§√§r√§ist√§ taustoitusta.
"""

def generate_answer(llm, contexts, question):
    allowed_urls = extract_allowed_urls(contexts)
    context_text = "\n---\n".join(contexts)
    raw = llm.invoke(PROMPT.format(context=context_text, question=question))
    clean = strip_disallowed_urls(raw, allowed_urls)
    return clean.strip()
```

- Arvioitu vaikutus: 
  - Vastauksen relevanssi +0.10‚Äì0.18
  - Kontekstin tarkkuus +0.03‚Äì0.06
  - URL-hallusinaatiot ~0 ‚Üí 0

2) P1: Cross-encoder re-rankkaus + pienemm√§t chunkit (v√§hemm√§n ‚Äúsivu√§√§nt√§‚Äù)
- Ongelma: Liian laajat chunkit ja pelkk√§ vektorihaku tuovat mukaan sivuavaa sis√§lt√∂√§.
- Ratkaisu:
  - Pilko dokumentit 300‚Äì500 tokenin chunkkeihin, 60‚Äì80 tokenin overlap.
  - K√§yt√§ cross-encoder -re-ranker (esim. ms-marco-MiniLM-L-6-v2) top-50 vektorihakutuloksen p√§√§lle, valitse top-5.
- Koodi:

```python
from sentence_transformers import CrossEncoder

reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

def rerank(query: str, passages: list[str], top_k: int = 5):
    pairs = [(query, p) for p in passages]
    scores = reranker.predict(pairs)
    ranked = sorted(zip(passages, scores), key=lambda x: x[1], reverse=True)
    return [p for p, s in ranked[:top_k]]
```

- Arvioitu vaikutus:
  - Vastauksen relevanssi +0.08‚Äì0.12
  - Kontekstin tarkkuus +0.04‚Äì0.07
  - Input-tokenit ‚àí10‚Äì20% (v√§hemm√§n turhaa kontekstia)

3) P2: MMR-kontekstikompressio + ‚Äúevidence highlighting‚Äù mallille
- Ongelma: Vaikka oikea chunk l√∂ytyy, mukana on viel√§ redundanttia teksti√§.
- Ratkaisu:
  - K√§yt√§ MMR:√§√§ (diversiteetti) top-k valintaan.
  - Tuota mallille ‚Äúevidence only‚Äù -tiivistelm√§ (lauseet, joissa vastauksen kannalta oleelliset avainsanat).
- Koodi (MMR):

```python
import numpy as np

def mmr(query_vec, doc_vecs, docs, k=5, lambda_mult=0.7):
    selected, candidates = [], list(range(len(docs)))
    selected_scores = []

    sim_to_query = np.dot(doc_vecs, query_vec)
    while len(selected) < k and candidates:
        mmr_scores = []
        for c in candidates:
            if not selected:
                diversity = 0
            else:
                diversity = max([np.dot(doc_vecs[c], doc_vecs[s]) for s in selected])
            score = lambda_mult * sim_to_query[c] - (1 - lambda_mult) * diversity
            mmr_scores.append((c, score))
        c_best = max(mmr_scores, key=lambda x: x[1])[0]
        selected.append(c_best)
        candidates.remove(c_best)
    return [docs[i] for i in selected]
```

- Arvioitu vaikutus:
  - Relevanssi +0.03‚Äì0.06
  - Tokenit ‚àí10‚Äì15%

4) P2: Intent- ja domain-reititys (HR/Matkalasku/Ty√∂aika)
- Ongelma: ‚Äúmix‚Äù-tilassa kysymykset voivat osua v√§√§r√§√§n dokumenttialueeseen.
- Ratkaisu:
  - Luokittele kysymys intenttiin (esim. ‚ÄúMatkalasku/URL‚Äù, ‚ÄúTy√∂aika-kirjaus‚Äù, ‚ÄúP√§iv√§rahat‚Äù) ja ohjaa domain-kohtaiseen indeksiin/rerankkeriin.
- Koodi (kevyt luokitin, esimerkki):

```python
import re

def route_domain(query: str) -> str:
    q = query.lower()
    if re.search(r'(matkalasku|p√§iv√§raha|kilometri|kuitti|netvisor.*(suomi|login))', q):
        return "travel_expense"
    if re.search(r'(ty√∂aika|kirjaa|minuutit|seuranta|poissaolo|vuosiloma)', q):
        return "time_tracking"
    return "general_hr"

# k√§yt√§ domain-kohtaista retrieveri√§
```

- Arvioitu vaikutus:
  - Relevanssi +0.04‚Äì0.08

5) P3: KKnowledge base -hygienia ja canonical mapping
- Ongelma: Dokumenteissa esiintyy useita URL-muotoja ja termej√§.
- Ratkaisu:
  - Lis√§√§ canonical mapping (esim. suomi.netvisor.fi) indeksiin ja promptiin n√§kyv√§n whitelistin l√§hteeksi.
  - Enrichaa dokumentteja metadatalla (url=canonical, doc_type, valid_from/valid_to).
- Koodi (URL normalisointi indeksoinnissa):

```python
CANONICAL = {
    "netvisor_login": "https://suomi.netvisor.fi",
}

def normalize_urls(text: str) -> str:
    return text.replace("https://login.netvisor.fi", CANONICAL["netvisor_login"])
```

- Arvioitu vaikutus:
  - Hallusinaatioiden v√§heneminen (URL) ‚Üí l√§hes 0
  - Relevanssi +0.02‚Äì0.04

6) P3: ‚ÄúEi l√∂ydy kontekstista‚Äù -fallback ja vastauspituusrajat
- Ongelma: Pitk√§t, ymp√§ripy√∂re√§t vastaukset ‚Üí relevanssi laskee.
- Ratkaisu:
  - Jos evidenssi√§ < kynnys, palauta fallback.
  - Rajoita vastaus 2‚Äì5 bulletiin, suora vastaus ensin.
- Koodi:

```python
def answer_or_fallback(contexts, question, llm, min_evidence_len=50):
    if sum(len(c) for c in contexts) < min_evidence_len:
        return "Ei l√∂ydy kontekstista."
    return generate_answer(llm, contexts, question)
```

- Arvioitu vaikutus:
  - Relevanssi +0.03‚Äì0.05
  - Totuudenmukaisuus +0.02‚Äì0.03

## üìà Implementointij√§rjestys ja vaikutusarviot
- Taulukko: prioriteetti, ty√∂m√§√§r√§, vaikutus

| Toimenpide | Prioriteetti | Ty√∂m√§√§r√§ | Vaikutus laatuun | Vaikutus kustannuksiin/latenssiin |
|---|:--:|:--:|:--:|:--:|
| ‚ÄúVain kontekstista‚Äù -prompt + URL guardrail | P1 | 0.5‚Äì1 pv | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (Relevanssi) | ~0 |
| Cross-encoder re-rankkaus + chunkkaus | P1 | 1‚Äì2 pv | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ | +10‚Äì20% latenssi |
| MMR-kompressio + evidence highlighting | P2 | 1 pv | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ | ‚àí10‚Äì15% tokenit |
| Intent/domain-reititys | P2 | 1 pv | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ | ~0 |
| Canonical URL -normalisointi | P3 | 0.5 pv | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ | ~0 |
| Fallback + pituusrajat | P3 | 0.5 pv | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ | ‚àí5‚Äì10% tokenit |

Arvio: Relevanssi 0.6888 ‚Üí 0.84‚Äì0.88 yhdist√§m√§ll√§ P1 + P2. RAGAS-keskiarvo > 0.86.

## üöÄ Pika-voitot (Quick Wins)
- Ota k√§ytt√∂√∂n ‚ÄúVain kontekstista‚Äù -prompt ja URL-whitelist-guardrail (koodi yll√§) ‚úÖ
- Chunkkaa dokumentit 300‚Äì500 tokeniin ja pienenn√§ top_k=3‚Äì5 kontekstiksi ‚úÖ
- Lis√§√§ vastauspituusrajat: ‚Äúvastaa 2‚Äì5 bulletilla, √§l√§ lis√§√§ ylim√§√§r√§ist√§ taustaa‚Äù ‚úÖ
- Canonicalisoi Netvisor-URL: ‚Äúhttps://suomi.netvisor.fi‚Äù indeksoinnissa ja vastauksissa ‚úÖ
- Lis√§√§ ‚ÄúEi l√∂ydy kontekstista‚Äù -fallback, jos evidenssi heikko ‚úÖ

## üî¨ A/B-testaussuunnitelma
- Tavoite: Nostaa Vastauksen relevanssi ‚â• 0.85 ilman totuudenmukaisuuden heikkenemist√§.
- Koeasetelma:
  - Populaatio: 150‚Äì300 HR/Netvisor-kysymyst√§ (syntettinen + aidot anonyymisoidut kysymykset).
  - Jaottelu: 50/50 Baseline vs Variantti (P1 + re-rankkaus). Stratifikoi intentin mukaan (Matkalasku, Ty√∂aika, Poissaolot).
  - Mittarit:
    - RAGAS: Answer Relevance (prim√§√§ri), Faithfulness, Context Precision/Recall
    - Hallusinaatioaste: osuus URL:ista, joita ei l√∂ydy kontekstista (tavoite 0%)
    - Tokenit/kysymys ja latenssi
  - Menetelm√§: Interleaved evaluation + bootstrap-luottamusv√§lit. 95% luottamustaso.
  - Kesto: 3‚Äì5 arkip√§iv√§√§ liikennevolyymin mukaan.
- Pys√§ytyskriteerit:
  - Relevanssi +‚â•0.10 parannus ja Faithfulness ¬±0.00‚Äì0.02 sis√§ll√§ (ei heikkenemist√§).
  - Ei merkitt√§v√§√§ latenssipiikki√§ (>25%).

## üìä Monitorointi ja jatkuva parantaminen
- Jatkuva RAGAS-ajo:
  - P√§ivitt√§inen batch 50 satunnaistetulle kysymykselle, tallennus mlflow/warehouse.
  - H√§lytys, jos:
    - Relevanssi < 0.80 2 per√§kk√§isen√§ p√§iv√§n√§
    - Hallusinaatio-URL-aste > 0.5%
- Telemetria:
  - Logita: kysymys, top-k kontekstit, valittu evidenssi, vastaus, k√§ytetyt URL:t, latenssi, tokenit.
- Driftin seuranta:
  - Dokumenttien versiointi (valid_from/valid_to), varoitus jos kontekstista l√∂ytyy ristiriitaisia URL-muotoja.
- S√§√§nn√∂lliset korjaukset:
  - Viikkokatselmoidaan heikoimmat 10 vastausta; lis√§t√§√§n testikantaan regressiotesteiksi.
- Automatisoitu validointi (esim. URL-politiikka):
  - Regex-tarkastus CI-putkessa: vastaus ei saa sis√§lt√§√§ URL:ia, joita ei l√∂ydy kontekstista.

## üìù Yhteenveto
- Nykytila
  - Korkea kontekstin kattavuus ja hyv√§ totuudenmukaisuus. Relevanssi j√§√§ j√§lkeen, mik√§ n√§kyy konkreettisina virhein√§ (URL-hallusinaatiot, off-topic-lis√§t).
- P√§√§ongelma
  - Generointi ei ole riitt√§v√§n ankkuroidusti kontekstissa; re-rankkaus ja chunkkaus eiv√§t viel√§ tee tarpeeksi selektiivist√§ evidenssin valintaa.
- Ratkaisu
  - P1: ‚ÄúVain kontekstista‚Äù -prompt + URL-whitelist-guardrail ja cross-encoder re-rankkaus sek√§ pienemm√§t chunkit. P2: MMR-kompressio ja domain-reititys. P3: Canonical URL -normalisointi ja fallbackit.
- Odotettu tulos
  - Vastauksen relevanssi 0.84‚Äì0.88, RAGAS-keskiarvo > 0.86, URL-hallusinaatiot ~0, tokenit ‚àí15‚Äì30%.
- Seuraavat askeleet
  - (1) Ota k√§ytt√∂√∂n P1-toimet ja p√§ivit√§ tuotantoprompti + guardrail-koodi.
  - (2) Ota k√§ytt√∂√∂n re-rankkaus ja chunkkaus; laske top_k=3‚Äì5.
  - (3) K√§ynnist√§ A/B-testi (150‚Äì300 kysymyst√§, 3‚Äì5 pv).
  - (4) Implementoi monitorointi ja h√§lytykset.
  - (5) Laajenna P2-toimiin (MMR, domain-reititys) testitulosten perusteella.