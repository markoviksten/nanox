# RAGAS-testituloksien Analyysi ja Optimointiehdotukset

## ğŸ“Š Yhteenveto tuloksista
- Kokonaisarvio
  - Jakautumat (kysymystyypit ja chunk-mÃ¤Ã¤rÃ¤t) osuvat hyvin tavoitteisiin.
  - Testikysymysten laatu kuitenkin kÃ¤rsii sisÃ¤llÃ¶llisistÃ¤ duplikaateista, katkaistuista ground truth -teksteistÃ¤ (â€...â€) ja rajallisesta monihyppyisyydestÃ¤ (3â€“5 chunkin aidosti vaativat kysymykset).
  - TÃ¤mÃ¤ testijoukko todennÃ¤kÃ¶isesti yliarvioi RAG-jÃ¤rjestelmÃ¤n suorituskykyÃ¤ (RAGAS-metriikoissa), koska vaikeat/kontrastiset ja harhauttavat testit puuttuvat.

- Taulukko metriikoista (tulos, tavoite, status)

| Metriikka | Tulos | Tavoite | Status |
|---|---:|---:|:--:|
| Kysymystyyppien jakauma (short/reason/synth) | 29.2% / 41.7% / 29.2% | 30% / 40% / 30% | âœ… |
| Chunk-jakauma (1/2/3/4/5) | 20.8/20.8/22.9/20.8/14.6% | 20/20/25/20/15% | ğŸŸ¡ (3-chunk âˆ’2.1%) |
| Duplikaattiaste (sisÃ¤llÃ¶lliset) | arviolta 30â€“35% | < 10% | ğŸ”´ |
| Ground truth -tÃ¤ydellisyys (ei â€...â€) | arviolta 15â€“25% katkaistu | 0% katkaisua | ğŸ”´ |
| Aidosti monihyppyiset kysymykset (â‰¥3 chunk) | arviolta 10â€“15% | â‰¥ 30% | ğŸ”´ |
| Aihediversiteetti (Netvisor vs. muut) | SelvÃ¤sti Netvisor-painotteinen | Tasapainoisempi | ğŸŸ¡ |
| Tokenit/kysymys (kokonais) | ~2344 | < 1500 | ğŸŸ¡ |
| Kustannus/kysymys | ~$0.00046 | < $0.001 | âœ… |
| Generointiaika/kysymys | ~5.8 s | < 6 s | âœ… |

### Keskeiset havainnot
- âœ… Vahvuudet
  - Jakaumat noudattavat tavoitetta lÃ¤hes tÃ¤smÃ¤lleen (sekÃ¤ kysymystyypeissÃ¤ ettÃ¤ chunk-mÃ¤Ã¤rissÃ¤).
  - Kustannus ja lÃ¤pimenoaika ovat erinomaisia tÃ¤hÃ¤n volyymiin.
  - Kysymykset heijastelevat oikeita jÃ¤rjestelmÃ¤termejÃ¤ (esim. Netvisor-tyÃ¶vaiheet, â€pakolliset kentÃ¤tâ€, â€pankkitunnuksillaâ€).
- âš ï¸ Kehityskohteet
  - SisÃ¤llÃ¶lliset duplikaatit: useita lÃ¤hes saman kysymyksen variaatioita (esim. lomien ja poissaolojen kirjaaminen Netvisorissa).
  - Ground truth -vastaukset useissa kohdissa katkaistuja (â€...â€), mikÃ¤ heikentÃ¤Ã¤ evaluoinnin luotettavuutta ja RAGAS faithfulness -tulkintaa.
  - Monihyppyisyyden puute: valtaosa kysymyksistÃ¤ ratkeaa yhdestÃ¤ lÃ¤hteestÃ¤; harhauttavia konteksteja ei ole.
  - Aihediversiteetti kapea: painottuu tyÃ¶aikaseurantaan/lomiin/matkalaskuihin; vÃ¤hemmÃ¤n sÃ¤Ã¤ntÃ¶tulkintoja, poikkeustilanteita ja numerisia reunaehtoja.
  - Token-efektiivisyys: ~2344 tokenia/kysymys â†’ voidaan kiristÃ¤Ã¤ ilman laadun alenemista.

## ğŸ¯ PÃ¤Ã¤ongelma
- Yksityiskohtainen ongelman kuvaus
  - Testijoukko ei riittÃ¤vÃ¤sti stressaa RAG-pinoa. Kun kysymykset ovat toistensa parafraaseja ja ratkeavat yksittÃ¤isestÃ¤ chunkista, retrieverin ja rerankerin puutteet eivÃ¤t nÃ¤y RAGAS-metriikoissa (context_precision, context_recall, faithfulness). Puuttuvat hard-negatives ja monihyppyisyys johtavat liian optimistisiin arvioihin.
  - Katkaistut ground truth -tekstit (â€...â€) estÃ¤vÃ¤t luotettavan faithfulness-arvioinnin, koska odotettu vastaus ei ole yksiselitteinen eikÃ¤ tÃ¤ydellinen.
- Konkreettiset esimerkit
  - Duplikaatit/variaatiot:
    - Q1, Q6, Q7, Q10, Q12, Q14: â€Miten lomat/poissaolot kirjataan Netvisorissa?â€ vain pienin muunnelmin.
    - Q21, Q23, Q26, Q28, Q31, Q34: toistavat samaa teemaa (miksi kirjata lomat/poissaolot Netvisoriin).
  - Katkaistut ground truthit:
    - Useita rivejÃ¤, esim. Q1, Q2, Q3, Q4 (â€...â€), jolloin tarkka odote ja mahdolliset numeriset ehdot puuttuvat.
  - Monihyppyisyyden puute:
    - Vaikka osa kysymyksistÃ¤ on merkitty 3â€“5 chunkiksi, vastaus ei edellytÃ¤ yhdistelyÃ¤ (usein toisteinen selite samasta prosessista).

## ğŸ”§ Optimointiehdotukset
- Priorisoidut toimenpiteet (P1, P2, P3)
- Jokaiselle: ongelma, ratkaisu, koodi, arvioitu vaikutus

1) P1: Testiaineiston rakenteellinen parannus (deduplikointi, tÃ¤ydet ground truthit, hard-negatives)
- Ongelma: Korkea duplikaattiaste, katkaistut ground truthit, helppoja yksichunk-kysymyksiÃ¤.
- Ratkaisu:
  - Deduplikoi kysymykset semanttisesti (clustering, threshold 0.88 cosine).
  - TÃ¤ydennÃ¤ ground truth -vastaukset 1â€“2 ytimekkÃ¤Ã¤seen, tÃ¤ydelliseen kappaleeseen ja lisÃ¤Ã¤ viitteet chunk_id-listana.
  - Luo 20â€“30% testijoukosta â€hard-negativeâ€ -asetuksilla: lisÃ¤Ã¤ sekaan tarkoituksella hyvin samankaltaisia mutta virheellisiÃ¤ konteksteja, ja arvioi context_precision.
- Koodi (deduplikointi ja GT-korjaus, esimerkki):
```python
# pip install sentence-transformers rapidfuzz pandas
from sentence_transformers import SentenceTransformer
from rapidfuzz import fuzz
import pandas as pd
import numpy as np

df = pd.read_json("nano_2advanced_testcases_aligned.json")  # columns: ["question","ground_truth","chunks",...]

# 1) Semanttinen deduplikointi
model = SentenceTransformer("intfloat/multilingual-e5-base")
emb = model.encode(df["question"].tolist(), normalize_embeddings=True, batch_size=64, show_progress_bar=True)

# Pairwise lÃ¤hestymistapa (nopea karsinta)
def cosine(a, b): return np.dot(a, b)

keep = []
removed = set()
for i in range(len(df)):
    if i in removed:
        continue
    keep.append(i)
    for j in range(i+1, len(df)):
        if j in removed:
            continue
        sim = cosine(emb[i], emb[j])
        if sim >= 0.88:
            # varmistetaan ettei ole vain lyhyt muutos (Levenshtein/ratiosim)
            if fuzz.token_sort_ratio(df.loc[i,"question"], df.loc[j,"question"]) >= 85:
                removed.add(j)

df_dedup = df.iloc[keep].reset_index(drop=True)

# 2) Ground truth -katkaisujen korjaus: poistetaan rivit, joissa '...' ja merkitÃ¤Ã¤n tÃ¤ydennettÃ¤vÃ¤ksi
def needs_fix(gt: str) -> bool:
    return "..." in gt or len(gt.strip()) < 20

df_dedup["gt_needs_fix"] = df_dedup["ground_truth"].apply(needs_fix)
df_fix = df_dedup[df_dedup["gt_needs_fix"]]

# -> TÃ¤ydennÃ¤ df_fix rivit ohjelmallisesti (LLM) tai kÃ¤sin, ja lisÃ¤Ã¤ viitteet: df_dedup["ground_truth_citations"] = [[chunk_ids],...]
df_dedup.to_json("testcases_clean.json", orient="records", force_ascii=False, indent=2)
```
- Arvioitu vaikutus:
  - RAGAS faithfulness ja relevancy tulkinta muuttuu realistisemmaksi (vÃ¤hemmÃ¤n â€helpohkonâ€ testin biasia).
  - Context_precision/recall erotteleva voima kasvaa (hard-negatives).
  - Duplikaattiasteen lasku < 10% â†’ parempi peitto.

2) P1: Hybrid retrieval + rerankkaus kÃ¤yttÃ¶Ã¶n ennen seuraavaa evaluointia
- Ongelma: Vaativammat (3â€“5 chunk) kysymykset edellyttÃ¤vÃ¤t tarkkaa hakua; nykyinen testijoukko ei paljasta virheitÃ¤, mutta tuotannossa ne korostuvat.
- Ratkaisu:
  - Ota kÃ¤yttÃ¶Ã¶n BM25 + Dense -yhdistelmÃ¤haku sekÃ¤ cross-encoder-rerankkaus (bge-reranker-v2) top-20 â†’ top-5.
- Koodi (LangChain-miniesimerkki):
```python
# pip install langchain faiss-cpu sentence-transformers rank_bm25
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever, EnsembleRetriever
from sentence_transformers import CrossEncoder

docs = [...]  # list of Documents (page_content, metadata)
emb_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-base")
vs = FAISS.from_documents(docs, emb_model)
dense_retriever = vs.as_retriever(search_type="similarity", search_kwargs={"k": 20})
bm25_retriever = BM25Retriever.from_documents(docs)
bm25_retriever.k = 20

ensemble = EnsembleRetriever(retrievers=[bm25_retriever, dense_retriever], weights=[0.5, 0.5])

# Cross-encoder reranker
reranker = CrossEncoder("BAAI/bge-reranker-v2-m3")

def retrieve(query, top_k=5):
    cands = ensemble.get_relevant_documents(query)
    pairs = [[query, d.page_content] for d in cands]
    scores = reranker.predict(pairs)
    ranked = [d for _, d in sorted(zip(scores, cands), key=lambda x: x[0], reverse=True)]
    return ranked[:top_k]
```
- Arvioitu vaikutus:
  - +10â€“25% context_precision ja +5â€“15% context_recall vaativissa multichunk-kysymyksissÃ¤.
  - Faithfulness paranee, kun huonoja (mutta lÃ¤heisiÃ¤) osumia putoaa pois.

3) P2: Chunkkaus ja pÃ¤Ã¤llekkÃ¤inen kontekstihallinta
- Ongelma: YhdessÃ¤ chunkissa on mahdollisesti liikaa heterogeenista sisÃ¤ltÃ¶Ã¤; monihyppyisyys ei synny luonnostaan.
- Ratkaisu:
  - Ota kÃ¤yttÃ¶Ã¶n semanttinen segmentointi (600â€“800 tokenia, 20â€“30% overlap), ja korosta metadataa (otsikko, alaotsikko) embeddingeissÃ¤.
- Koodi (yksinkertaistettu split + overlap):
```python
# pip install tiktoken
import tiktoken

def tokenize(text, model="gpt-4o-mini"):
    enc = tiktoken.get_encoding("cl100k_base")
    return enc.encode(text)

def chunk_text(text, max_tokens=800, overlap=200):
    toks = tokenize(text)
    chunks = []
    start = 0
    while start < len(toks):
        end = min(start + max_tokens, len(toks))
        chunk = toks[start:end]
        chunks.append(chunk)
        start = end - overlap
        if start < 0: start = 0
        if end == len(toks): break
    return chunks
```
- Arvioitu vaikutus:
  - LisÃ¤Ã¤ aidosti yhdisteltÃ¤viÃ¤ pÃ¤tkiÃ¤ â†’ kasvattaa monihyppyisten kysymysten laatua ja nostaa context_recallia.

4) P2: Kysymysgeneraation ohjaus: pakota monihyppyisyys ja numeriset reunaehdot
- Ongelma: Kysymykset toistavat samaa teemaa eivÃ¤tkÃ¤ vaadi laskentaa/ristiriitojen ratkaisua.
- Ratkaisu:
  - Prompt-sÃ¤Ã¤nnÃ¶t: vÃ¤hintÃ¤Ã¤n 30% kysymyksistÃ¤ vaatii kahden eri dokumenttiosan yhdistelyÃ¤; vÃ¤hintÃ¤Ã¤n 20% sisÃ¤ltÃ¤Ã¤ numerisia ehtoja (esim. kesto, prosentit, koodit).
  - LisÃ¤Ã¤ â€disambiguationâ€-kysymyksiÃ¤ (samankaltaiset termit eri jÃ¤rjestelmissÃ¤).
- Koodi (generaattoripromptin skeleton, OpenAI):
```python
# pip install openai
from openai import OpenAI
client = OpenAI()

system = """Laadi 48 testikysymystÃ¤ seuraavilla ehdoilla:
- type distribution: short 30%, reasoning 40%, synthesis 30%
- chunks: 1:20%, 2:20%, 3:25%, 4:20%, 5:15%
- vÃ¤hintÃ¤Ã¤n 30% kysymyksistÃ¤ vaatii yhdistelyÃ¤ â‰¥2 erillisestÃ¤ chunkista
- vÃ¤hintÃ¤Ã¤n 20% sisÃ¤ltÃ¤Ã¤ numeerisia ehtoja (koodit, pÃ¤ivÃ¤t, prosentit, rajat)
- lisÃ¤Ã¤ 20% disambiguation-kysymyksiÃ¤, joissa kaksi samankaltaista kÃ¤sitettÃ¤ erotetaan
- vÃ¤ltÃ¤ semanttisia duplikaatteja (cosine sim < 0.85 aiempiin)
Palauta jokaiselle kysymykselle tÃ¤ydellinen ground truth ja lista viite-chunk_id:istÃ¤.
"""

resp = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[{"role":"system","content":system},{"role":"user","content":"KÃ¤ytÃ¤ lÃ¤hdettÃ¤ vdb_chunks.json (tiivistelmÃ¤t metadatasta)."}],
    temperature=0.4
)
```
- Arvioitu vaikutus:
  - Nostaa RAGAS faithfulnessin erottelua (vÃ¤hemmÃ¤n helppoja, enemmÃ¤n tarkkuutta vaativia tapauksia) ja lisÃ¤Ã¤ testien realistisuutta.

5) P3: Vastauspromptin guardrailit ja pituusohjaus
- Ongelma: LLM voi tuottaa hallusinaatioita tai laveita vastauksia, mikÃ¤ sekoittaa faithfulnessin.
- Ratkaisu:
  - LisÃ¤Ã¤ sÃ¤Ã¤ntÃ¶: jos konteksti ei riitÃ¤, palauta â€INSUFFICIENT_CONTEXTâ€.
  - Pituusohjaus: short_factual â‰¤ 2 lausetta; reasoning 3â€“6; synthesis 5â€“8 + lÃ¤hdeviitteet.
- Koodi (vastauspromptin runko):
```python
RAG_SYSTEM_PROMPT = """
Vastaa ainoastaan annetuista konteksteista. Jos tieto ei lÃ¶ydy varmasti, palauta 'INSUFFICIENT_CONTEXT'.
- short_factual: max 2 lausetta
- reasoning: 3-6 lausetta, perustele viittauksin
- synthesis: 5-8 lausetta, yhdistÃ¤ useita lÃ¤hteitÃ¤ ja lisÃ¤Ã¤ [chunk_id:t]
Ã„lÃ¤ lisÃ¤Ã¤ ulkoista tietoa.
"""
```
- Arvioitu vaikutus:
  - Faithfulness kasvaa, context_precision paranee (vÃ¤hemmÃ¤n ylimÃ¤Ã¤rÃ¤istÃ¤), ja mittaus on vakaampi.

6) P3: Token-efektiivisyys ja kustannusten optimointi
- Ongelma: ~2344 tokenia/kysymys voidaan supistaa.
- Ratkaisu:
  - Kontekstin tiivistys ennen mallille syÃ¶ttÃ¶Ã¤ (MMR-trimmi, duplikaattikatkaisu), vastauspituusrajat, cache.
- Koodi (MMR-trimmi):
```python
from langchain.retrievers import MMRRetriever

mmr_retriever = vs.as_retriever(search_type="mmr", search_kwargs={"k": 20, "fetch_k": 50, "lambda_mult": 0.5})
```
- Arvioitu vaikutus:
  - âˆ’20â€“35% tokenit/kysymys ilman vastauslaadun heikkenemistÃ¤.

## ğŸ“ˆ ImplementointijÃ¤rjestys ja vaikutusarviot
- Taulukko: prioriteetti, tyÃ¶mÃ¤Ã¤rÃ¤, vaikutus

| Prioriteetti | Toimenpide | TyÃ¶mÃ¤Ã¤rÃ¤ | Vaikutus RAGAS-metriikoihin |
|---|---|---:|---:|
| P1 | Deduplikointi + GT-tÃ¤ydennys + hard-negatives | 2â€“4 pv | Faithfulness/Precision +15â€“30% |
| P1 | Hybrid retrieval + cross-encoder rerank | 2â€“3 pv | Context_precision +10â€“25%, Recall +5â€“15% |
| P2 | Chunkkaus (800 tok, 20â€“30% overlap) | 1â€“2 pv | Recall +5â€“10% monihypyissÃ¤ |
| P2 | Generointipromptin sÃ¤Ã¤ntÃ¶jen tiukennus | 0.5â€“1 pv | Vaikeustaso â†‘, mittauksen erottelu â†‘ |
| P3 | Guardrailit + pituusohjaus | 0.5 pv | Faithfulness +5â€“10% |
| P3 | Token-efektiivisyys (MMR, cache) | 1 pv | âˆ’20â€“35% tokenit/kysymys |

## ğŸš€ Pika-voitot (Quick Wins)
- Poista â€...â€ ground truth -teksteistÃ¤ ja lisÃ¤Ã¤ chunk-viitteet jokaiselle testille (1 tyÃ¶pÃ¤ivÃ¤).
- Aja semanttinen deduplikointi (threshold 0.88) ja korvaa poistuneet uudentyyppisillÃ¤, numeerisilla tai disambiguation-kysymyksillÃ¤.
- Nosta 3-chunk -osuus tÃ¤smÃ¤lleen 25%:iin ja lisÃ¤Ã¤ vÃ¤hintÃ¤Ã¤n 8 uutta aidosti 4â€“5 chunkin monihyppyistÃ¤ kysymystÃ¤.
- LisÃ¤Ã¤ 10 â€harhautusâ€-tapausta (lÃ¤heiset mutta virheelliset kontekstit) context_precisionin mittaamiseksi.
- Ota kÃ¤yttÃ¶Ã¶n cross-encoder-rerankkaus (bge-reranker-v2-m3) heti: tyypillisesti nopein parannus kontekstin relevanssiin.

## ğŸ”¬ A/B-testaussuunnitelma
- Koeasetelma
  - A (baseline): nykyinen retriever + ilman rerankkausta.
  - B (parannettu): hybrid (BM25+dense) + cross-encoder-rerankkaus + uudet testit (dedup + hard-negatives).
- Otoskoko ja stratifiointi
  - 200â€“300 kysymystÃ¤, stratifioitu kysymystyypin (short/reason/synth) ja chunk-mÃ¤Ã¤rÃ¤n (1â€“5) mukaan.
- Mitattavat metriikat (RAGAS)
  - answer_relevancy (tavoite â‰¥ 0.90)
  - faithfulness (tavoite â‰¥ 0.85)
  - context_precision (tavoite â‰¥ 0.70)
  - context_recall (tavoite â‰¥ 0.80)
- PysÃ¤ytyskriteerit
  - B voittaa, jos kaikkien metriikoiden mediaani paranee ja vÃ¤hintÃ¤Ã¤n kahdessa (precision/faithfulness) ero > +5%-yks.
- Koodiluonnos (ragas-arvio):
```python
# pip install ragas datasets
from ragas import evaluate
from ragas.metrics import answer_relevancy, faithfulness, context_precision, context_recall
from datasets import Dataset

def to_ds(rows):
    # rows: list of dict: {"question","answer","contexts","ground_truth"}
    return Dataset.from_list(rows)

ds_A = to_ds(rows_A)  # baseline vastaukset + kontekstit
ds_B = to_ds(rows_B)  # parannetun pipelinen vastaukset + kontekstit

metrics = [answer_relevancy, faithfulness, context_precision, context_recall]
report_A = evaluate(ds_A, metrics=metrics)
report_B = evaluate(ds_B, metrics=metrics)

print("A:", report_A)
print("B:", report_B)
```

## ğŸ“Š Monitorointi ja jatkuva parantaminen
- PÃ¤ivittÃ¤inen regressiotesti: ajetaan 50â€“100 satunnaista testiÃ¤ (stratifioitu).
- Aikasarjaseuranta: tallenna metriikat (faithfulness, ctx_precision/recall, answer_relevancy), tokenit/kysymys, kesto/kysymys.
- HÃ¤lytykset: jos faithfulness < 0.80 tai context_precision laskee >10% viikon keskiarvosta â†’ Slack-hÃ¤lytys.
- Drift-seuranta: dokumenttivektorien jakauman muutos (cosine center shift), kysymysten embedding-jakauma.
- Koodiluonnos (Prometheus-metriikat):
```python
# pip install prometheus_client
from prometheus_client import Gauge, push_to_gateway

g_faith = Gauge('ragas_faithfulness', 'RAGAS faithfulness score')
g_prec = Gauge('ragas_context_precision', 'RAGAS context precision')
g_recl = Gauge('ragas_context_recall', 'RAGAS context recall')
g_relv = Gauge('ragas_answer_relevancy', 'RAGAS answer relevancy')

def push_metrics(r):
    g_faith.set(r["faithfulness"])
    g_prec.set(r["context_precision"])
    g_recl.set(r["context_recall"])
    g_relv.set(r["answer_relevancy"])
    push_to_gateway('http://prometheus-pushgateway:9091', job='rag_eval', registry=None)
```

## ğŸ“ Yhteenveto
- Nykytila
  - Testigenerointi on kustannustehokasta ja jakaumat osuvat tavoitteisiin, mutta testien laatu (duplikaatit, katkaistut ground truthit, vÃ¤hÃ¤inen monihyppyisyys) heikentÃ¤Ã¤ evaluoinnin realistisuutta.
- PÃ¤Ã¤ongelma
  - RAGAS-mittaus todennÃ¤kÃ¶isesti yliarvioi suorituskyvyn, koska testit eivÃ¤t sisÃ¤llÃ¤ riittÃ¤vÃ¤sti vaikeita, harhauttavia tai usean lÃ¤hteen yhdistelyÃ¤ vaativia tapauksia.
- Ratkaisu
  - P1: Deduplikointi, tÃ¤ydet ground truthit viitteineen, hard-negatives.
  - P1: Hybrid retrieval + cross-encoder-rerankkaus.
  - P2: Parempi chunkkaus ja generointipromptin sÃ¤Ã¤ntÃ¶jen tiukennus (monihyppy, numerot, disambiguation).
  - P3: Guardrailit vastausvaiheeseen ja token-efektiivisyyden parannukset.
- Odotettu tulos
  - Faithfulness +10â€“30%, context_precision +10â€“25%, context_recall +5â€“15%. Mittausten erottelu kasvaa ja tuotannon signaali vastaa paremmin evaluointia.
- Seuraavat askeleet
  - PÃ¤ivÃ¤ 1â€“2: Deduplikointi + GT-korjaukset + hard-negatives, lisÃ¤Ã¤ 8â€“12 monihyppyistÃ¤ kysymystÃ¤.
  - PÃ¤ivÃ¤ 2â€“3: Ota kÃ¤yttÃ¶Ã¶n hybrid retrieval + reranker; tee A/B-mittaus.
  - PÃ¤ivÃ¤ 4: SÃ¤Ã¤dÃ¤ chunkkaus ja generointipromptti; aja regressiosetti; julkaise monitorointi ja hÃ¤lytykset.